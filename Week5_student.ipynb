{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkIzELs9PIf1"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7UGc5j8uPIf4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from bs4 import BeautifulSoup\n",
        "import string\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIdBfukCPIf5"
      },
      "source": [
        "### 1. Read in csv file and create Dataframe & check shape."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TqU6yYr3PIf6",
        "outputId": "7fc61e9c-6d2e-4b5d-84a8-8a3e5e05e5bc",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'<html><h2>What is nlp??? </h2></html>\\nNatural Language Processing, or NLP for short, is broadly defined as the automatic manipulation of natural language, like speech and text, by software.\\nThe study of natural language processing has been around for more than 50 years and grew out of the field of linguistics with the rise of computers.\\n(In this post), you will discover what natural language processing is and why it is so important.\\nAfter reading this post, you will know => What natural language is and how it is different from other types of data.'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str_data = \"\"\"<html><h2>What is nlp??? </h2></html>\n",
        "Natural Language Processing, or NLP for short, is broadly defined as the automatic manipulation of natural language, like speech and text, by software.\n",
        "The study of natural language processing has been around for more than 50 years and grew out of the field of linguistics with the rise of computers.\n",
        "(In this post), you will discover what natural language processing is and why it is so important.\n",
        "After reading this post, you will know => What natural language is and how it is different from other types of data.\"\"\"\n",
        "str_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkJNPWqIPIf6"
      },
      "source": [
        "### 2-1. Cleaning - Remove HTML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "VBFLY9kNPIf7",
        "outputId": "5a84b504-1238-49e8-b010-74fd7868d960"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What is nlp??? \n",
            "Natural Language Processing, or NLP for short, is broadly defined as the automatic manipulation of natural language, like speech and text, by software.\n",
            "The study of natural language processing has been around for more than 50 years and grew out of the field of linguistics with the rise of computers.\n",
            "(In this post), you will discover what natural language processing is and why it is so important.\n",
            "After reading this post, you will know => What natural language is and how it is different from other types of data.\n"
          ]
        }
      ],
      "source": [
        "def remove_html(text_data):\n",
        "    \"\"\"\n",
        "    remove_html takes raw text and removes html tags from the text.\n",
        "    \"\"\"\n",
        "\n",
        "    soup = BeautifulSoup(text_data, \"lxml\")\n",
        "    return soup.get_text()\n",
        "\n",
        "processed_text = remove_html(str_data)\n",
        "print(processed_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkiHrX1XPIf7"
      },
      "source": [
        "### 2-2. Cleaning - Remove punctuation(구두점) & Lower case"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "HgPejbxRPIf8",
        "outputId": "fd5ede0b-bb91-45a1-883c-58a5bc31391d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Punctuation:  !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
          ]
        }
      ],
      "source": [
        "## Check English's punctuation\n",
        "print('Punctuation: ', string.punctuation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "MjpeAR7fPIf8"
      },
      "outputs": [],
      "source": [
        "def remove_punctuation(text):\n",
        "    sent =[]\n",
        "    for t in text.split(' '):\n",
        "        no_punct = \"\".join([c for c in t if c not in string.punctuation])\n",
        "        sent.append(no_punct)\n",
        " \n",
        "    sentence = \" \".join(s for s in sent)\n",
        "    return sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "u43RvcfGPIf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What is nlp \n",
            "Natural Language Processing or NLP for short is broadly defined as the automatic manipulation of natural language like speech and text by software\n",
            "The study of natural language processing has been around for more than 50 years and grew out of the field of linguistics with the rise of computers\n",
            "In this post you will discover what natural language processing is and why it is so important\n",
            "After reading this post you will know  What natural language is and how it is different from other types of data\n"
          ]
        }
      ],
      "source": [
        "rmv_punc_sentence = remove_punctuation(processed_text)\n",
        "print(rmv_punc_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "klIvSSkLPIf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "what is nlp \n",
            "natural language processing or nlp for short is broadly defined as the automatic manipulation of natural language like speech and text by software\n",
            "the study of natural language processing has been around for more than 50 years and grew out of the field of linguistics with the rise of computers\n",
            "in this post you will discover what natural language processing is and why it is so important\n",
            "after reading this post you will know  what natural language is and how it is different from other types of data\n"
          ]
        }
      ],
      "source": [
        "lowwer_sentence = rmv_punc_sentence.lower()\n",
        "print(lowwer_sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-H85pkvPIf9"
      },
      "source": [
        "### 3. Lemmatization & Tokenization with spacy library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "uIOsVf_EPIf9"
      },
      "outputs": [],
      "source": [
        "## using \"spacy\" library\n",
        "import spacy\n",
        "\n",
        "## Load the installed model \"en_core_web_sm\" into \"nlp\"\n",
        "nlp = spacy.load('en_core_web_sm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "tnSVFgrxPIf9"
      },
      "outputs": [],
      "source": [
        "## 'doc' is a sequence of Token objects\n",
        "## it holds all information about the tokens, their linguistic features and their relationships.\n",
        "doc = nlp(lowwer_sentence.strip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "enQ8SPs5PIf-"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "WRITE THE CODE\n",
        "\"\"\"\n",
        "tok_lem_sentence[:15]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "WyT9L5L0PIf-"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['what',\n",
              " 'be',\n",
              " 'nlp',\n",
              " '\\n',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " 'or',\n",
              " 'nlp',\n",
              " 'for',\n",
              " 'short',\n",
              " 'be',\n",
              " 'broadly',\n",
              " 'define',\n",
              " 'as']"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tok_lem_sentence = [token.lemma_ for token in doc]\n",
        "tok_lem_sentence[:15]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIxe259WPIf-"
      },
      "source": [
        "### 4. Remove stop words(불용어: 큰 의미가 없는 단어)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "b0TlfvrSPIf-"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /Users/woo-\n",
            "[nltk_data]     hyun/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# if you do not have 'stopwords' then run the below statement.\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Hdo7D4hkPIf-",
        "outputId": "c6915742-8a1a-49b6-c002-7137c98f1984"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an']\n",
            "198\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "print (stopwords.words ('english' ) [ :10])\n",
        "print (len(stopwords.words ('english' )))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "7RU9ldlSPIf-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['what', 'be', 'nlp', '\\n', 'natural', 'language', 'processing', 'or', 'nlp', 'for', 'short', 'be', 'broadly', 'define', 'as', 'the', 'automatic', 'manipulation', 'of', 'natural', 'language', 'like', 'speech', 'and', 'text', 'by', 'software', '\\n', 'the', 'study', 'of', 'natural', 'language', 'processing', 'have', 'be', 'around', 'for', 'more', 'than', '50', 'year', 'and', 'grow', 'out', 'of', 'the', 'field', 'of', 'linguistic', 'with', 'the', 'rise', 'of', 'computer', '\\n', 'in', 'this', 'post', 'you', 'will', 'discover', 'what', 'natural', 'language', 'processing', 'be', 'and', 'why', 'it', 'be', 'so', 'important', '\\n', 'after', 'read', 'this', 'post', 'you', 'will', 'know', ' ', 'what', 'natural', 'language', 'be', 'and', 'how', 'it', 'be', 'different', 'from', 'other', 'type', 'of', 'datum'] \n",
            "\n",
            "['nlp', '\\n', 'natural', 'language', 'processing', 'nlp', 'short', 'broadly', 'define', 'automatic', 'manipulation', 'natural', 'language', 'like', 'speech', 'text', 'software', '\\n', 'study', 'natural', 'language', 'processing', 'around', '50', 'year', 'grow', 'field', 'linguistic', 'rise', 'computer', '\\n', 'post', 'discover', 'natural', 'language', 'processing', 'important', '\\n', 'read', 'post', 'know', ' ', 'natural', 'language', 'different', 'type', 'datum']\n",
            "\n",
            "Removed word:  {'grow', 'have', 'after', 'datum'}\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "print(tok_lem_sentence, '\\n')\n",
        "rmv_sw_sentence = [w for w in tok_lem_sentence if  not w  in stop_words]\n",
        "print(rmv_sw_sentence)\n",
        "removed_word = [word for word in tok_lem_sentence if not word in rmv_punc_sentence]\n",
        "\n",
        "print(\"\\nRemoved word: \", set(removed_word))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9CgcSUUPIf-"
      },
      "source": [
        "### 5. Make dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "eocjd9X1PIf-",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "dictionary = {}\n",
        "\n",
        "def make_frequency_dict(text):\n",
        "    for word in text:\n",
        "        if word not in dictionary:\n",
        "            dictionary[word] =0\n",
        "        dictionary[word] += 1\n",
        "\n",
        "make_frequency_dict(rmv_sw_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "K7b11kItPIf-",
        "outputId": "2db32a8f-c64b-4c2a-b4b3-0016bcc90eea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(dictionary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "jj6BYVNGPIf_"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'nlp': 2,\n",
              " '\\n': 4,\n",
              " 'natural': 5,\n",
              " 'language': 5,\n",
              " 'processing': 3,\n",
              " 'short': 1,\n",
              " 'broadly': 1,\n",
              " 'define': 1,\n",
              " 'automatic': 1,\n",
              " 'manipulation': 1,\n",
              " 'like': 1,\n",
              " 'speech': 1,\n",
              " 'text': 1,\n",
              " 'software': 1,\n",
              " 'study': 1,\n",
              " 'around': 1,\n",
              " '50': 1,\n",
              " 'year': 1,\n",
              " 'grow': 1,\n",
              " 'field': 1,\n",
              " 'linguistic': 1,\n",
              " 'rise': 1,\n",
              " 'computer': 1,\n",
              " 'post': 2,\n",
              " 'discover': 1,\n",
              " 'important': 1,\n",
              " 'read': 1,\n",
              " 'know': 1,\n",
              " ' ': 1,\n",
              " 'different': 1,\n",
              " 'type': 1,\n",
              " 'datum': 1}"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "bOKjwK6ePIf_"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('natural', 5),\n",
              " ('language', 5),\n",
              " ('\\n', 4),\n",
              " ('processing', 3),\n",
              " ('nlp', 2),\n",
              " ('post', 2),\n",
              " ('short', 1),\n",
              " ('broadly', 1),\n",
              " ('define', 1),\n",
              " ('automatic', 1),\n",
              " ('manipulation', 1),\n",
              " ('like', 1),\n",
              " ('speech', 1),\n",
              " ('text', 1),\n",
              " ('software', 1),\n",
              " ('study', 1),\n",
              " ('around', 1),\n",
              " ('50', 1),\n",
              " ('year', 1),\n",
              " ('grow', 1),\n",
              " ('field', 1),\n",
              " ('linguistic', 1),\n",
              " ('rise', 1),\n",
              " ('computer', 1),\n",
              " ('discover', 1),\n",
              " ('important', 1),\n",
              " ('read', 1),\n",
              " ('know', 1),\n",
              " (' ', 1),\n",
              " ('different', 1),\n",
              " ('type', 1),\n",
              " ('datum', 1)]"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab_sorted = sorted(dictionary.items(), key=lambda x:x[1], reverse = True)\n",
        "vocab_sorted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "K204ZIWcPIf_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'natural': 1, 'language': 2, '\\n': 3, 'processing': 4, 'nlp': 5, 'post': 6}\n"
          ]
        }
      ],
      "source": [
        "word_to_index = {}\n",
        "i = 0\n",
        "\n",
        "for (word, frequency) in vocab_sorted :\n",
        "    if frequency > 1:\n",
        "        word_to_index[word] = i\n",
        "        i += 1\n",
        "        word_to_index[word] = i\n",
        "\n",
        "print(word_to_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "IqtEE9ddPIf_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'natural': 1, 'language': 2, '\\n': 3, 'processing': 4, 'nlp': 5, 'post': 6, 'OOV': 7}\n"
          ]
        }
      ],
      "source": [
        "word_to_index['OOV'] = len(word_to_index) + 1\n",
        "\n",
        "print(word_to_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkB9t6qrPIf_"
      },
      "source": [
        "### 6. Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "pdc0jOvfPIf_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['nlp', '\\n', 'natural', 'language', 'processing', 'nlp', 'short', 'broadly', 'define', 'automatic', 'manipulation', 'natural', 'language', 'like', 'speech', 'text', 'software', '\\n', 'study', 'natural', 'language', 'processing', 'around', '50', 'year', 'grow', 'field', 'linguistic', 'rise', 'computer', '\\n', 'post', 'discover', 'natural', 'language', 'processing', 'important', '\\n', 'read', 'post', 'know', ' ', 'natural', 'language', 'different', 'type', 'datum']\n",
            "[5, 3, 1, 2, 4, 5, 7, 7, 7, 7, 7, 1, 2, 7, 7, 7, 7, 3, 7, 1, 2, 4, 7, 7, 7, 7, 7, 7, 7, 7, 3, 6, 7, 1, 2, 4, 7, 3, 7, 6, 7, 7, 1, 2, 7, 7, 7]\n"
          ]
        }
      ],
      "source": [
        "encoded = []\n",
        "\n",
        "print(rmv_sw_sentence)\n",
        "\n",
        "for w in rmv_sw_sentence:\n",
        "    try:\n",
        "        encoded.append(word_to_index[w])\n",
        "    except KeyError:\n",
        "        encoded.append(word_to_index['OOV'])\n",
        "        \n",
        "print(encoded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vNYyLCYPIf_"
      },
      "source": [
        "## THE END 🌟"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "anyname",
      "language": "python",
      "name": "myenv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
